{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Open Court Data India","text":"<p>A collection of scrapers and tools for accessing Indian court data.</p>"},{"location":"#overview","title":"Overview","text":"<p>The Open Court Data India project provides tools for scraping, processing, and analyzing data from various Indian courts. The project aims to make court data more accessible and usable for researchers, legal professionals, and the general public.</p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#centralized-utilities-structure","title":"Centralized Utilities Structure","text":"<p>The project has been refactored to use a centralized utilities structure:</p> <ul> <li><code>common.py</code>: General utility functions (directory management, filename cleaning, date extraction)</li> <li><code>pdf_utils.py</code>: PDF handling functions (text extraction, structured data parsing)</li> <li><code>html_utils.py</code>: HTML processing functions (text extraction, navigation page detection)</li> <li><code>scraper_utils.py</code>: Scraper-specific utilities (downloading, content type checking, metadata saving)</li> </ul>"},{"location":"#consistent-directory-structure","title":"Consistent Directory Structure","text":"<p>The Delhi High Court scrapers follow a consistent directory structure for saving data:</p> <ul> <li>Base path: <code>/Users/varunh/Documents/ecourts-scrapers/data/</code></li> <li>Delhi HC base scraper: <code>/Users/varunh/Documents/ecourts-scrapers/data/delhi_hc/</code></li> <li>Delhi HC cause list scraper: <code>/Users/varunh/Documents/ecourts-scrapers/data/delhi_hc/cause_lists/</code></li> </ul>"},{"location":"#parallel-processing-capabilities","title":"Parallel Processing Capabilities","text":"<p>The Delhi HC scraper has been enhanced with parallel processing capabilities:</p> <ul> <li>Parallel PDF Downloading: Using ThreadPoolExecutor with configurable workers</li> <li>Parallel Gemini API Processing: For enhanced metadata extraction</li> <li>Configurable Options: Control parallelism and resource usage</li> </ul>"},{"location":"#database-integration","title":"Database Integration","text":"<p>The project includes PostgreSQL database integration for storing and querying court data:</p> <ul> <li>Structured schema for courts, benches, judges, cause lists, and cases</li> <li>API for programmatic access to the database</li> <li>Tagging system for categorizing and filtering cases</li> </ul>"},{"location":"#implementation-status","title":"Implementation Status","text":"<p>The following table shows the implementation status of scrapers for various Indian courts:</p> Court Cause Lists Judgments Orders Case Status Delhi High Court \u2705 \u274c \u274c \u274c Supreme Court \u274c \u274c \u274c \u274c Bombay High Court \u274c \u274c \u274c \u274c Madras High Court \u274c \u274c \u274c \u274c Calcutta High Court \u274c \u274c \u274c \u274c Karnataka High Court \u274c \u274c \u274c \u274c Allahabad High Court \u274c \u274c \u274c \u274c Gujarat High Court \u274c \u274c \u274c \u274c <p>\u2705 - Implemented | \u274c - Not yet implemented</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Check out the Installation Guide to get started with the project.</p>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Installation Guide</li> <li>Quick Start Guide</li> <li>Database Integration</li> <li>API Documentation</li> <li>Developer Guide</li> </ul>"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>IMPORTANT NOTICE: The author takes no responsibility for the quality and performance of this code. All data obtained through these scrapers is the respective copyright of its owner. The author claims ownership only of the code, not the data. Use at your own risk.</p>"},{"location":"about/changelog/","title":"Changelog","text":""},{"location":"about/changelog/#v010-2025-03-23","title":"v0.1.0 (2025-03-23)","text":"<p>Initial release of the Open Court Data India project.</p>"},{"location":"about/changelog/#features","title":"Features","text":"<ul> <li>Delhi HC Cause List Scraper</li> <li>Download cause lists from Delhi High Court website</li> <li>Extract metadata from PDFs</li> <li> <p>Parallel processing for improved performance</p> </li> <li> <p>Data Processing</p> </li> <li>Integration with Google's Gemini API</li> <li>Structured data extraction from PDFs</li> <li> <p>Parallel processing of PDFs</p> </li> <li> <p>Database Integration</p> </li> <li>PostgreSQL database schema</li> <li>Database connector class</li> <li> <p>Query interface</p> </li> <li> <p>Tagging System</p> </li> <li>Auto-tagging based on patterns</li> <li>Manual tagging interface</li> <li> <p>Tag-based filtering</p> </li> <li> <p>API and Frontend</p> </li> <li>FastAPI backend</li> <li>React frontend</li> <li> <p>API client</p> </li> <li> <p>Documentation</p> </li> <li>MkDocs with Material theme</li> <li>Comprehensive user and developer guides</li> <li>API documentation</li> </ul>"},{"location":"about/changelog/#known-issues","title":"Known Issues","text":"<ul> <li>Limited to Delhi High Court cause lists only</li> <li>Gemini API processing may have limitations for complex PDFs</li> <li>Frontend has basic functionality only</li> </ul>"},{"location":"about/changelog/#future-plans","title":"Future Plans","text":"<ul> <li>Add support for more courts</li> <li>Add support for judgments, orders, and case status</li> <li>Improve data extraction accuracy</li> <li>Enhance frontend functionality</li> <li>Add analytics and visualization tools</li> </ul>"},{"location":"about/license/","title":"License","text":""},{"location":"about/license/#code-license","title":"Code License","text":"<p>The Open Court Data India project code is licensed under the Apache License, Version 2.0.</p> <pre><code>                             Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n</code></pre> <p>Copyright 2025 Varun Hemachandran</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\");    you may not use this file except in compliance with the License.    You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software    distributed under the License is distributed on an \"AS IS\" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    See the License for the specific language governing permissions and    limitations under the License.</p>"},{"location":"about/license/#data-license","title":"Data License","text":"<p>IMPORTANT NOTICE: The author takes no responsibility for the quality and performance of this code. All data obtained through these scrapers is the respective copyright of its owner. The author claims ownership only of the code, not the data.</p> <p>Court data is subject to the respective copyright policies of the courts from which it is obtained. This project does not grant any rights to the data itself.</p>"},{"location":"about/license/#third-party-licenses","title":"Third-Party Licenses","text":"<p>This project uses several third-party libraries, each with its own license:</p> <ul> <li>FastAPI: MIT License</li> <li>PostgreSQL: PostgreSQL License (similar to MIT)</li> <li>React: MIT License</li> <li>MkDocs: BSD License</li> <li>MkDocs Material: MIT License</li> </ul> <p>Please refer to the respective projects for their full license terms.</p>"},{"location":"api-reference/database/","title":"Database API Reference","text":"<p>This section provides detailed API documentation for the database connector and related functions in the Open Court Data India project.</p>"},{"location":"api-reference/database/#database-connector","title":"Database Connector","text":"<p>The database connector provides an interface for interacting with the PostgreSQL database. It handles connections, transactions, and CRUD operations for court data.</p>"},{"location":"api-reference/database/#database-schema","title":"Database Schema","text":"<p>The database schema is defined in <code>db/schema.sql</code>. It includes tables for:</p> <ul> <li>Courts</li> <li>Benches</li> <li>Judges</li> <li>Cause Lists</li> <li>Cases</li> <li>Tags</li> <li>Case Tags</li> </ul> <p>For the full schema definition, refer to the schema.sql file.</p>"},{"location":"api-reference/scrapers/","title":"Scrapers API Reference","text":"<p>This section provides detailed API documentation for the scraper classes and functions in the Open Court Data India project.</p>"},{"location":"api-reference/scrapers/#delhi-high-court-scrapers","title":"Delhi High Court Scrapers","text":""},{"location":"api-reference/scrapers/#base-scraper","title":"Base Scraper","text":"<p>The base scraper provides common functionality for all Delhi High Court scrapers. It handles:</p> <ul> <li>Setting up the output directory structure</li> <li>Managing file paths and naming conventions</li> <li>Providing common utility methods</li> </ul>"},{"location":"api-reference/scrapers/#cause-list-scraper","title":"Cause List Scraper","text":"<p>The Delhi High Court Cause List Scraper is responsible for:</p> <ul> <li>Downloading cause list PDFs from the Delhi High Court website</li> <li>Extracting text from the PDFs using PyPDF2</li> <li>Parsing the extracted text to identify cases, judges, and other metadata</li> <li>Saving the structured data to JSON files</li> <li>Optionally processing the data with the Gemini API for enhanced metadata extraction</li> </ul>"},{"location":"api-reference/scrapers/#parallel-processing","title":"Parallel Processing","text":"<p>As noted in the project memories, the Delhi HC scraper has been enhanced with parallel processing capabilities:</p> <ol> <li>Parallel PDF Downloading: </li> <li>Using <code>ThreadPoolExecutor</code> to download multiple PDFs concurrently</li> <li>Configurable max_workers (default: 5) to control parallelism</li> <li> <p>Implemented proper synchronization to avoid race conditions</p> </li> <li> <p>Parallel Gemini API Processing:</p> </li> <li>Using <code>ThreadPoolExecutor</code> to process PDFs with Gemini API concurrently</li> <li>Separate processing phase after all downloads complete</li> <li>Configurable max_workers (default: 3) to avoid API rate limiting</li> </ol>"},{"location":"api-reference/utilities/","title":"Utilities API Reference","text":"<p>This section provides detailed API documentation for the utility modules in the Open Court Data India project.</p>"},{"location":"api-reference/utilities/#common-utilities","title":"Common Utilities","text":"<p>The <code>common.py</code> module contains general utility functions used throughout the project:</p> <ul> <li>Directory management functions</li> <li>Filename cleaning utilities</li> <li>Date extraction from filenames and text</li> <li>Logging setup and configuration</li> </ul>"},{"location":"api-reference/utilities/#pdf-utilities","title":"PDF Utilities","text":"<p>The <code>pdf_utils.py</code> module provides functions for working with PDF files:</p> <ul> <li>Text extraction from PDFs using PyPDF2</li> <li>Structured data parsing from PDF text</li> <li>PDF metadata extraction</li> <li>Page-by-page content processing</li> </ul>"},{"location":"api-reference/utilities/#html-utilities","title":"HTML Utilities","text":"<p>The <code>html_utils.py</code> module contains functions for processing HTML content:</p> <ul> <li>Text extraction from HTML documents</li> <li>Navigation page detection</li> <li>HTML parsing and cleaning</li> <li>Link extraction and processing</li> </ul>"},{"location":"api-reference/utilities/#scraper-utilities","title":"Scraper Utilities","text":"<p>The <code>scraper_utils.py</code> module provides utilities specific to web scraping:</p> <ul> <li>File downloading with proper error handling</li> <li>Content type checking</li> <li>Metadata saving and management</li> <li>Rate limiting and retry logic</li> </ul>"},{"location":"api-reference/utilities/#gemini-utilities","title":"Gemini Utilities","text":"<p>The <code>gemini_utils.py</code> module contains functions for interacting with the Google Gemini API:</p> <ul> <li>API client setup and configuration</li> <li>Text processing and analysis</li> <li>Structured data extraction from unstructured text</li> <li>Error handling and rate limiting for API calls</li> </ul>"},{"location":"developer-guide/architecture/","title":"Architecture","text":"<p>This document provides an overview of the architecture of the Open Court Data India project.</p>"},{"location":"developer-guide/architecture/#system-overview","title":"System Overview","text":"<p>The project follows a modular architecture with several key components:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Scrapers    \u2502    \u2502 Data        \u2502    \u2502 Database    \u2502    \u2502 API &amp;       \u2502\n\u2502 Module      \u2502\u2500\u2500\u2500&gt;\u2502 Processor   \u2502\u2500\u2500\u2500&gt;\u2502 Storage     \u2502&lt;\u2500\u2500\u2500\u2502 Frontend    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"developer-guide/architecture/#component-architecture","title":"Component Architecture","text":""},{"location":"developer-guide/architecture/#scrapers-module","title":"Scrapers Module","text":"<p>The scrapers module is responsible for downloading court data from various sources. It follows a hierarchical structure:</p> <pre><code>scrapers/\n\u251c\u2500\u2500 base_scraper.py         # Base scraper class\n\u251c\u2500\u2500 delhi_hc/               # Delhi High Court scrapers\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 base_scraper.py     # Base Delhi HC scraper\n\u2502   \u2514\u2500\u2500 cause_lists/        # Cause list scraper\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 cause_list_scraper.py\n\u2514\u2500\u2500 ...                     # Other court scrapers\n</code></pre> <p>Key features: - Inheritance Hierarchy: Specialized scrapers inherit from more general ones - Consistent Interface: All scrapers implement a common interface - Parallel Processing: Efficient downloading with ThreadPoolExecutor - Error Handling: Robust error handling and retry mechanisms</p>"},{"location":"developer-guide/architecture/#data-processor","title":"Data Processor","text":"<p>The data processor module converts unstructured court data into structured formats using the Gemini API:</p> <pre><code>utils/\n\u251c\u2500\u2500 data_processor.py       # Main data processor\n\u2514\u2500\u2500 gemini_utils.py         # Gemini API utilities\n</code></pre> <p>Key features: - Gemini API Integration: Uses Google's Gemini API for PDF processing - Structured Data Extraction: Converts PDFs to structured JSON - Parallel Processing: Processes multiple PDFs concurrently - Error Handling: Handles API errors and rate limiting</p>"},{"location":"developer-guide/architecture/#database-storage","title":"Database Storage","text":"<p>The database module handles storing and retrieving court data:</p> <pre><code>db/\n\u251c\u2500\u2500 connector.py            # Database connector class\n\u2514\u2500\u2500 schema.sql              # Database schema\n</code></pre> <p>Key features: - PostgreSQL Integration: Stores data in a PostgreSQL database - Object-Relational Mapping: Maps database tables to Python objects - Query Interface: Provides methods for querying the database - Transaction Management: Ensures data consistency</p>"},{"location":"developer-guide/architecture/#api-and-frontend","title":"API and Frontend","text":"<p>The API and frontend modules provide a user interface for accessing court data:</p> <pre><code>api/\n\u2514\u2500\u2500 app.py                  # FastAPI application\n\nfrontend/\n\u251c\u2500\u2500 public/                 # Static assets\n\u2514\u2500\u2500 src/                    # React components\n    \u251c\u2500\u2500 components/         # UI components\n    \u2514\u2500\u2500 services/           # API client\n</code></pre> <p>Key features: - REST API: FastAPI backend with documented endpoints - React Frontend: Modern UI with React and Tailwind CSS - API Client: JavaScript client for the API - Responsive Design: Mobile-friendly interface</p>"},{"location":"developer-guide/architecture/#utilities","title":"Utilities","text":"<p>The project includes several utility modules:</p> <pre><code>utils/\n\u251c\u2500\u2500 __init__.py             # Package initialization\n\u251c\u2500\u2500 common.py               # Common utility functions\n\u251c\u2500\u2500 pdf_utils.py            # PDF processing utilities\n\u251c\u2500\u2500 html_utils.py           # HTML processing utilities\n\u251c\u2500\u2500 scraper_utils.py        # Scraper utilities\n\u251c\u2500\u2500 data_processor.py       # Data processing utilities\n\u2514\u2500\u2500 gemini_utils.py         # Gemini API utilities\n</code></pre> <p>These utilities provide reusable functions for common tasks, following the centralized utilities structure established in the project.</p>"},{"location":"developer-guide/architecture/#data-flow","title":"Data Flow","text":"<p>The data flows through the system as follows:</p> <ol> <li>Scraping: The scrapers download PDFs from court websites and save them to the <code>data/</code> directory</li> <li>Processing: The data processor extracts structured data from the PDFs using the Gemini API</li> <li>Storage: The structured data is stored in the PostgreSQL database</li> <li>Retrieval: The API and frontend retrieve data from the database and present it to the user</li> </ol>"},{"location":"developer-guide/architecture/#parallel-processing","title":"Parallel Processing","text":"<p>The project implements parallel processing at two key points:</p> <ol> <li>PDF Downloading: Uses ThreadPoolExecutor to download multiple PDFs concurrently</li> <li>Configurable max_workers (default: 5)</li> <li> <p>Thread-safe operations to prevent race conditions</p> </li> <li> <p>Gemini API Processing: Uses ThreadPoolExecutor to process PDFs with Gemini API concurrently</p> </li> <li>Configurable max_workers (default: 3)</li> <li>Rate limiting to avoid API throttling</li> </ol>"},{"location":"developer-guide/architecture/#directory-structure","title":"Directory Structure","text":"<p>The project follows a consistent directory structure for storing data:</p> <pre><code>data/\n\u2514\u2500\u2500 delhi_hc/\n    \u2514\u2500\u2500 cause_lists/\n        \u2514\u2500\u2500 YYYY-MM-DD/\n            \u251c\u2500\u2500 pdf1.pdf\n            \u251c\u2500\u2500 pdf1.json\n            \u251c\u2500\u2500 pdf2.pdf\n            \u2514\u2500\u2500 pdf2.json\n</code></pre> <p>This structure is maintained by the <code>utils.common</code> module, which provides functions for creating and managing directories.</p>"},{"location":"developer-guide/architecture/#configuration","title":"Configuration","text":"<p>The project uses a combination of:</p> <ul> <li>config.yaml: Main configuration file</li> <li>.env: Environment variables for sensitive information</li> <li>Command-line arguments: Override configuration for specific runs</li> </ul>"},{"location":"developer-guide/architecture/#pipeline-integration","title":"Pipeline Integration","text":"<p>The <code>run_pipeline.py</code> script integrates all components into a complete workflow:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Scrape      \u2502\u2500\u2500\u2500&gt;\u2502 Process     \u2502\u2500\u2500\u2500&gt;\u2502 Store       \u2502\u2500\u2500\u2500&gt;\u2502 Tag         \u2502\n\u2502 Cause Lists \u2502    \u2502 with Gemini \u2502    \u2502 in Database \u2502    \u2502 Cases       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>This pipeline can be run with a single command:</p> <pre><code>python run_pipeline.py\n</code></pre>"},{"location":"developer-guide/architecture/#future-architecture","title":"Future Architecture","text":"<p>The project is designed to be extensible, with plans to add:</p> <ul> <li>More Court Scrapers: Support for additional Indian courts</li> <li>Additional Document Types: Support for judgments, orders, and case status</li> <li>Advanced Search: Full-text search and filtering</li> <li>Analytics Dashboard: Visualizations and statistics</li> <li>API Authentication: Secure access to the API</li> <li>Distributed Processing: Scale to handle larger volumes of data</li> </ul>"},{"location":"developer-guide/code-of-conduct/","title":"Code of Conduct","text":""},{"location":"developer-guide/code-of-conduct/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"developer-guide/code-of-conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"developer-guide/code-of-conduct/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"developer-guide/code-of-conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"developer-guide/code-of-conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at varun.hemachandran@gmail.com. The project team will review and investigate all complaints, and will respond in a way that it deems appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.</p> <p>Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.</p>"},{"location":"developer-guide/code-of-conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html</p>"},{"location":"developer-guide/code-style/","title":"Code Style Guide","text":"<p>This document outlines the coding standards and style guidelines for the Open Court Data India project. Following these guidelines ensures consistency across the codebase and makes it easier for contributors to understand and maintain the code.</p>"},{"location":"developer-guide/code-style/#python-style-guide","title":"Python Style Guide","text":""},{"location":"developer-guide/code-style/#general-guidelines","title":"General Guidelines","text":"<ul> <li>Follow PEP 8 style guide for Python code.</li> <li>Use 4 spaces for indentation (no tabs).</li> <li>Keep line length to a maximum of 100 characters.</li> <li>Use meaningful variable and function names.</li> <li>Add docstrings to all modules, classes, and functions.</li> </ul>"},{"location":"developer-guide/code-style/#imports","title":"Imports","text":"<ul> <li>Group imports in the following order:</li> <li>Standard library imports</li> <li>Related third-party imports</li> <li>Local application/library specific imports</li> <li>Within each group, imports should be sorted alphabetically.</li> </ul> <pre><code># Standard library imports\nimport os\nimport sys\nfrom datetime import datetime\n\n# Third-party imports\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\n# Local imports\nfrom utils.common import create_directory\nfrom utils.pdf_utils import extract_text_from_pdf\n</code></pre>"},{"location":"developer-guide/code-style/#docstrings","title":"Docstrings","text":"<ul> <li>Use Google-style docstrings for all modules, classes, and functions.</li> <li>Include type hints in function signatures.</li> </ul> <pre><code>def extract_date_from_filename(filename: str) -&gt; Optional[datetime]:\n    \"\"\"\n    Extract date from a filename.\n\n    Args:\n        filename: The filename to extract date from\n\n    Returns:\n        A datetime object if date is found, None otherwise\n\n    Raises:\n        ValueError: If the filename format is not recognized\n    \"\"\"\n    # Function implementation\n</code></pre>"},{"location":"developer-guide/code-style/#error-handling","title":"Error Handling","text":"<ul> <li>Use specific exception types rather than catching all exceptions.</li> <li>Log exceptions with appropriate context.</li> </ul> <pre><code>try:\n    # Code that might raise an exception\n    data = process_file(file_path)\nexcept FileNotFoundError:\n    logger.error(f\"File not found: {file_path}\")\n    # Handle the error appropriately\nexcept ValueError as e:\n    logger.error(f\"Invalid data in file {file_path}: {str(e)}\")\n    # Handle the error appropriately\n</code></pre>"},{"location":"developer-guide/code-style/#sql-style-guide","title":"SQL Style Guide","text":"<ul> <li>Use uppercase for SQL keywords (SELECT, INSERT, etc.).</li> <li>Use snake_case for table and column names.</li> <li>Include comments for complex queries.</li> </ul> <pre><code>-- Get all cases with a specific tag\nSELECT c.id, c.case_number, c.title\nFROM cases c\nJOIN case_tags ct ON c.id = ct.case_id\nJOIN tags t ON ct.tag_id = t.id\nWHERE t.name = 'important';\n</code></pre>"},{"location":"developer-guide/code-style/#git-commit-messages","title":"Git Commit Messages","text":"<ul> <li>Use the imperative mood in the subject line.</li> <li>Limit the subject line to 50 characters.</li> <li>Capitalize the subject line.</li> <li>Do not end the subject line with a period.</li> <li>Separate subject from body with a blank line.</li> <li>Wrap the body at 72 characters.</li> <li>Use the body to explain what and why vs. how.</li> </ul> <p>Example: <pre><code>Add parallel processing to Delhi HC scraper\n\n- Implement ThreadPoolExecutor for PDF downloads\n- Add configuration options for controlling parallelism\n- Ensure thread safety for shared resources\n</code></pre></p>"},{"location":"developer-guide/code-style/#code-organization","title":"Code Organization","text":"<ul> <li>Keep modules focused on a single responsibility.</li> <li>Use classes to encapsulate related functionality.</li> <li>Separate utility functions into appropriate modules.</li> <li>Follow the project's directory structure conventions.</li> </ul> <p>By following these guidelines, you'll help maintain a clean, consistent, and maintainable codebase for the Open Court Data India project.</p>"},{"location":"developer-guide/contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to the Open Court Data India project! This guide will help you get started with contributing to the project.</p>"},{"location":"developer-guide/contributing/#getting-started","title":"Getting Started","text":"<ol> <li> <p>Fork the repository: Click the \"Fork\" button at the top right of the GitHub repository.</p> </li> <li> <p>Clone your fork: Clone your fork to your local machine.</p> </li> </ol> <pre><code>git clone https://github.com/your-username/open-court-data-india.git\ncd open-court-data-india\n</code></pre> <ol> <li> <p>Set up the development environment: Follow the installation guide to set up your development environment.</p> </li> <li> <p>Create a branch: Create a branch for your changes.</p> </li> </ol> <pre><code>git checkout -b feature/your-feature-name\n</code></pre>"},{"location":"developer-guide/contributing/#development-workflow","title":"Development Workflow","text":"<ol> <li> <p>Make your changes: Make your changes to the codebase.</p> </li> <li> <p>Test your changes: Make sure your changes work as expected.</p> </li> <li> <p>Update documentation: Update the documentation if necessary.</p> </li> <li> <p>Commit your changes: Commit your changes with a descriptive commit message.</p> </li> </ol> <pre><code>git add .\ngit commit -m \"Add feature: your feature description\"\n</code></pre> <ol> <li>Push your changes: Push your changes to your fork.</li> </ol> <pre><code>git push origin feature/your-feature-name\n</code></pre> <ol> <li>Create a pull request: Create a pull request from your fork to the main repository.</li> </ol>"},{"location":"developer-guide/contributing/#code-style","title":"Code Style","text":"<p>Please follow the code style guide when making changes to the codebase.</p>"},{"location":"developer-guide/contributing/#adding-a-new-court-scraper","title":"Adding a New Court Scraper","text":"<p>To add a new court scraper:</p> <ol> <li>Create a new directory: Create a new directory for the court under the <code>scrapers</code> directory.</li> </ol> <pre><code>scrapers/\n\u2514\u2500\u2500 new_court/\n    \u251c\u2500\u2500 __init__.py\n    \u2514\u2500\u2500 base_scraper.py\n</code></pre> <ol> <li>Create a base scraper: Create a base scraper for the court that inherits from the <code>BaseScraper</code> class.</li> </ol> <pre><code>from scrapers.base_scraper import BaseScraper\n\nclass NewCourtScraper(BaseScraper):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.court_name = \"New Court\"\n        self.court_code = \"new_court\"\n        self.court_dir = f\"data/{self.court_code}/\"\n        self.base_url = \"https://newcourt.gov.in\"\n</code></pre> <ol> <li>Create specialized scrapers: Create specialized scrapers for different types of documents (cause lists, judgments, etc.).</li> </ol> <pre><code>scrapers/\n\u2514\u2500\u2500 new_court/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 base_scraper.py\n    \u2514\u2500\u2500 cause_lists/\n        \u251c\u2500\u2500 __init__.py\n        \u2514\u2500\u2500 cause_list_scraper.py\n</code></pre> <ol> <li> <p>Implement the scraper: Implement the scraper following the project's architecture and best practices.</p> </li> <li> <p>Add tests: Add tests for the new scraper.</p> </li> <li> <p>Update documentation: Update the documentation to include the new scraper.</p> </li> </ol>"},{"location":"developer-guide/contributing/#adding-a-new-feature","title":"Adding a New Feature","text":"<p>To add a new feature:</p> <ol> <li> <p>Discuss the feature: Open an issue to discuss the feature before implementing it.</p> </li> <li> <p>Implement the feature: Implement the feature following the project's architecture and best practices.</p> </li> <li> <p>Add tests: Add tests for the new feature.</p> </li> <li> <p>Update documentation: Update the documentation to include the new feature.</p> </li> </ol>"},{"location":"developer-guide/contributing/#reporting-bugs","title":"Reporting Bugs","text":"<p>If you find a bug, please report it by opening an issue on the GitHub repository.</p> <p>Please include:</p> <ul> <li>A clear and descriptive title</li> <li>Steps to reproduce the bug</li> <li>Expected behavior</li> <li>Actual behavior</li> <li>Any error messages or logs</li> <li>Your environment (OS, Python version, etc.)</li> </ul>"},{"location":"developer-guide/contributing/#feature-requests","title":"Feature Requests","text":"<p>If you have an idea for a new feature, please open an issue on the GitHub repository.</p> <p>Please include:</p> <ul> <li>A clear and descriptive title</li> <li>A detailed description of the feature</li> <li>Why the feature would be useful</li> <li>Any relevant examples or mockups</li> </ul>"},{"location":"developer-guide/contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>Please follow the code of conduct when contributing to the project.</p>"},{"location":"developer-guide/contributing/#license","title":"License","text":"<p>By contributing to the Open Court Data India project, you agree that your contributions will be licensed under the MIT License.</p>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>This guide explains how to configure the Open Court Data India project for your needs.</p>"},{"location":"getting-started/configuration/#configuration-files","title":"Configuration Files","text":"<p>The project uses several configuration mechanisms:</p> <ol> <li>config.yaml: Main configuration file for scrapers and utilities</li> <li>.env: Environment variables for sensitive information</li> <li>Command-line arguments: Override configuration for specific runs</li> </ol>"},{"location":"getting-started/configuration/#main-configuration-configyaml","title":"Main Configuration (config.yaml)","text":"<p>The <code>config.yaml</code> file in the project root contains configuration for scrapers and utilities:</p> <pre><code># Output directory for downloaded data\noutput_dir: \"data\"\n\n# Logging configuration\nlogging:\n  level: \"INFO\"\n  format: \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n  file: null  # Set to a path to enable file logging\n\n# Scraper configuration\nscrapers:\n  # Delhi High Court scraper\n  delhi_hc:\n    # Base URL for the Delhi High Court website\n    base_url: \"https://delhihighcourt.nic.in\"\n\n    # Cause list scraper\n    cause_list:\n      # URL for cause lists\n      url: \"https://delhihighcourt.nic.in/causelist\"\n      # Number of retries for failed requests\n      max_retries: 3\n      # Timeout for requests in seconds\n      timeout: 30\n      # User agent for requests\n      user_agent: \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n      # Parallel processing configuration\n      parallel_downloads: true\n      download_workers: 5\n      parallel_processing: true\n      processing_workers: 3\n\n# Gemini API configuration\ngemini:\n  # API key (prefer setting this in .env file)\n  api_key: null\n  # Model to use\n  model: \"gemini-pro-vision\"\n  # Temperature for generation\n  temperature: 0.2\n  # Maximum tokens to generate\n  max_output_tokens: 2048\n  # Top-k\n  top_k: 40\n  # Top-p\n  top_p: 0.8\n</code></pre>"},{"location":"getting-started/configuration/#environment-variables-env","title":"Environment Variables (.env)","text":"<p>Sensitive information such as API keys and database credentials should be stored in a <code>.env</code> file in the project root:</p> <pre><code># Database connection\nDB_USER=ecourts\nDB_PASSWORD=your_password\nDB_HOST=localhost\nDB_PORT=5432\nDB_NAME=ecourts\n\n# API keys\nGEMINI_API_KEY=your_gemini_api_key\n\n# Application settings\nDEBUG=False\nLOG_LEVEL=INFO\n</code></pre> <p>The project includes a <code>.env.example</code> file that you can copy and modify:</p> <pre><code>cp .env.example .env\n# Edit .env with your credentials\n</code></pre>"},{"location":"getting-started/configuration/#command-line-arguments","title":"Command-Line Arguments","text":"<p>Most scripts in the project accept command-line arguments to override configuration:</p>"},{"location":"getting-started/configuration/#scraper-arguments","title":"Scraper Arguments","text":"<pre><code>python -m scrapers.delhi_hc.cause_lists.cause_list_scraper --help\n</code></pre> <p>Common arguments include:</p> <ul> <li><code>--output</code>, <code>-o</code>: Specify a custom output directory</li> <li><code>--date</code>: Specify a date to scrape (YYYY-MM-DD)</li> <li><code>--debug</code>: Enable debug logging</li> <li><code>--config</code>: Specify a custom configuration file</li> </ul>"},{"location":"getting-started/configuration/#pipeline-arguments","title":"Pipeline Arguments","text":"<pre><code>python run_pipeline.py --help\n</code></pre> <p>Pipeline arguments include:</p> <ul> <li><code>--date</code>: Specify a date to process (YYYY-MM-DD)</li> <li><code>--days</code>: Number of days to scrape (default: 1)</li> <li><code>--no-scrape</code>: Skip scraping step</li> <li><code>--no-process</code>: Skip processing step</li> <li><code>--no-tag</code>: Skip tagging step</li> <li><code>--parallel</code>: Enable parallel processing</li> <li><code>--download-workers</code>: Number of download workers (default: 5)</li> <li><code>--processing-workers</code>: Number of processing workers (default: 3)</li> <li><code>--debug</code>: Enable debug logging</li> </ul>"},{"location":"getting-started/configuration/#query-arguments","title":"Query Arguments","text":"<pre><code>python query_db.py --help\n</code></pre> <p>Query arguments include:</p> <ul> <li><code>--list-dates</code>: List all available dates</li> <li><code>--date</code>: Query by date (YYYY-MM-DD)</li> <li><code>--bench</code>: Filter by bench number</li> <li><code>--case</code>: Search for a specific case</li> <li><code>--tag</code>: Filter by tag</li> <li><code>--pretty</code>: Pretty-print JSON output</li> <li><code>--json</code>: Output as JSON</li> </ul>"},{"location":"getting-started/configuration/#tagging-arguments","title":"Tagging Arguments","text":"<pre><code>python tag_cases.py --help\n</code></pre> <p>Tagging arguments include:</p> <ul> <li><code>--list-tags</code>: List all tags in the database</li> <li><code>--auto-tag</code>: Auto-tag all cases based on patterns</li> <li><code>--case-id</code>: Specify a case ID for manual tagging</li> <li><code>--add-tags</code>: Add tags to a case</li> <li><code>--remove-tags</code>: Remove tags from a case</li> </ul>"},{"location":"getting-started/configuration/#directory-structure","title":"Directory Structure","text":"<p>The project follows a consistent directory structure for storing data:</p> <pre><code>data/\n\u2514\u2500\u2500 delhi_hc/\n    \u2514\u2500\u2500 cause_lists/\n        \u2514\u2500\u2500 YYYY-MM-DD/\n            \u251c\u2500\u2500 pdf1.pdf\n            \u251c\u2500\u2500 pdf1.json\n            \u251c\u2500\u2500 pdf2.pdf\n            \u2514\u2500\u2500 pdf2.json\n</code></pre> <p>This structure is maintained by the <code>utils.common</code> module, which provides functions for creating and managing directories.</p>"},{"location":"getting-started/configuration/#parallel-processing-configuration","title":"Parallel Processing Configuration","text":"<p>The project supports parallel processing for both downloading and API processing:</p> <pre><code># In config.yaml\nscrapers:\n  delhi_hc:\n    cause_list:\n      parallel_downloads: true\n      download_workers: 5\n      parallel_processing: true\n      processing_workers: 3\n</code></pre> <p>You can override these settings with command-line arguments:</p> <pre><code>python run_pipeline.py --parallel --download-workers 5 --processing-workers 3\n</code></pre> <p>The parallel processing implementation uses <code>ThreadPoolExecutor</code> for both downloading and API processing, with proper synchronization to avoid race conditions.</p>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide will help you set up the Open Court Data India project on your local machine.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Python 3.8 or higher</li> <li>PostgreSQL 12 or higher (optional, for database integration)</li> <li>Node.js 16 or higher (optional, for frontend development)</li> </ul>"},{"location":"getting-started/installation/#basic-installation","title":"Basic Installation","text":"<ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/varun-heman/open-court-data-india.git\ncd open-court-data-india\n</code></pre> <ol> <li>Create a virtual environment and activate it:</li> </ol> <pre><code>python -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n</code></pre> <ol> <li>Install the required dependencies:</li> </ol> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/installation/#database-setup-optional","title":"Database Setup (Optional)","text":"<p>If you want to use the database integration features:</p> <ol> <li>Install PostgreSQL if not already installed:</li> </ol> <pre><code># macOS (using Homebrew)\nbrew install postgresql\nbrew services start postgresql\n\n# Ubuntu/Debian\nsudo apt-get update\nsudo apt-get install postgresql postgresql-contrib\nsudo systemctl start postgresql\n</code></pre> <ol> <li>Create a database and user:</li> </ol> <pre><code># Connect to PostgreSQL\npsql postgres\n\n# Create user and database\nCREATE USER ecourts WITH PASSWORD 'your_password';\nCREATE DATABASE ecourts OWNER ecourts;\n\\q\n</code></pre> <ol> <li>Initialize the database schema:</li> </ol> <pre><code># Set environment variables\nexport DB_USER=ecourts\nexport DB_PASSWORD=your_password\nexport DB_HOST=localhost\nexport DB_PORT=5432\nexport DB_NAME=ecourts\n\n# Initialize database schema\npsql -U ecourts -d ecourts -f db/schema.sql\n</code></pre> <ol> <li>Create a <code>.env</code> file in the project root with your database credentials:</li> </ol> <pre><code>DB_USER=ecourts\nDB_PASSWORD=your_password\nDB_HOST=localhost\nDB_PORT=5432\nDB_NAME=ecourts\n</code></pre>"},{"location":"getting-started/installation/#gemini-api-setup","title":"Gemini API Setup","text":"<p>To use the Gemini API for processing PDFs:</p> <ol> <li> <p>Obtain a Gemini API key from Google AI Studio</p> </li> <li> <p>Add your API key to the <code>.env</code> file:</p> </li> </ol> <pre><code>GEMINI_API_KEY=your_gemini_api_key\n</code></pre>"},{"location":"getting-started/installation/#frontend-setup-optional","title":"Frontend Setup (Optional)","text":"<p>If you want to use the frontend:</p> <ol> <li>Navigate to the frontend directory:</li> </ol> <pre><code>cd frontend\n</code></pre> <ol> <li>Install the required dependencies:</li> </ol> <pre><code>npm install\n</code></pre> <ol> <li>Start the development server:</li> </ol> <pre><code>npm start\n</code></pre>"},{"location":"getting-started/installation/#documentation-setup-optional","title":"Documentation Setup (Optional)","text":"<p>To build and serve the documentation locally:</p> <ol> <li>Install the documentation dependencies:</li> </ol> <pre><code>pip install mkdocs mkdocs-material pymdown-extensions mkdocstrings mkdocstrings-python\n</code></pre> <ol> <li>Serve the documentation:</li> </ol> <pre><code>mkdocs serve\n</code></pre> <ol> <li>Open your browser to http://localhost:8000 to view the documentation.</li> </ol>"},{"location":"getting-started/installation/#verifying-the-installation","title":"Verifying the Installation","text":"<p>To verify that everything is set up correctly:</p> <ol> <li>Run the basic scraper:</li> </ol> <pre><code>python -m scrapers.delhi_hc.cause_lists.cause_list_scraper --debug\n</code></pre> <ol> <li>If you've set up the database, run the complete pipeline:</li> </ol> <pre><code>python run_pipeline.py --debug\n</code></pre> <p>If both commands run without errors, your installation is successful!</p>"},{"location":"getting-started/quick-start/","title":"Quick Start Guide","text":"<p>This guide will help you quickly get started with the Open Court Data India project.</p>"},{"location":"getting-started/quick-start/#basic-usage","title":"Basic Usage","text":""},{"location":"getting-started/quick-start/#running-the-delhi-hc-cause-list-scraper","title":"Running the Delhi HC Cause List Scraper","text":"<p>To scrape Delhi High Court cause lists for today:</p> <pre><code># Activate your virtual environment\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Run the scraper\npython -m scrapers.delhi_hc.cause_lists.cause_list_scraper\n</code></pre> <p>The scraper will download cause list PDFs to the <code>data/delhi_hc/cause_lists/YYYY-MM-DD/</code> directory.</p>"},{"location":"getting-started/quick-start/#running-the-complete-pipeline","title":"Running the Complete Pipeline","text":"<p>To run the complete pipeline (scrape, process, store, and tag):</p> <pre><code># Run the pipeline for today\npython run_pipeline.py\n\n# Run the pipeline for a specific date\npython run_pipeline.py --date 2025-03-23\n</code></pre>"},{"location":"getting-started/quick-start/#querying-the-database","title":"Querying the Database","text":"<p>After running the pipeline, you can query the database:</p> <pre><code># List all available dates\npython query_db.py --list-dates\n\n# Query by date\npython query_db.py --date 2025-03-23 --pretty\n\n# Search for a specific case\npython query_db.py --case \"W.P.(C)-6483/2021\" --pretty\n\n# Filter by tags\npython query_db.py --tag \"education\" --pretty\n</code></pre>"},{"location":"getting-started/quick-start/#tagging-cases","title":"Tagging Cases","text":"<p>You can add tags to cases in the database:</p> <pre><code># List all tags in the database\npython tag_cases.py --list-tags\n\n# Auto-tag all cases based on patterns\npython tag_cases.py --auto-tag\n\n# Manually tag a specific case\npython tag_cases.py --case-id \"case_uuid\" --add-tags \"important,urgent\"\n</code></pre>"},{"location":"getting-started/quick-start/#starting-the-api-server","title":"Starting the API Server","text":"<p>To start the API server:</p> <pre><code># Navigate to the api directory\ncd api\n\n# Start the server\nuvicorn app:app --reload\n</code></pre> <p>The API will be available at http://localhost:8000.</p>"},{"location":"getting-started/quick-start/#starting-the-frontend","title":"Starting the Frontend","text":"<p>To start the frontend development server:</p> <pre><code># Navigate to the frontend directory\ncd frontend\n\n# Install dependencies (first time only)\nnpm install\n\n# Start the development server\nnpm start\n</code></pre> <p>The frontend will be available at http://localhost:3000.</p>"},{"location":"getting-started/quick-start/#parallel-processing","title":"Parallel Processing","text":"<p>The scraper and processor support parallel processing for improved performance:</p> <pre><code># Run the pipeline with parallel processing\npython run_pipeline.py --parallel --download-workers 5 --processing-workers 3\n</code></pre>"},{"location":"getting-started/quick-start/#common-commands","title":"Common Commands","text":"<p>Here are some common commands for reference:</p> <pre><code># Scrape Delhi HC cause lists for a specific date\npython -m scrapers.delhi_hc.cause_lists.cause_list_scraper --date 2025-03-23\n\n# Process PDFs with Gemini API\npython -m utils.data_processor --court delhi_hc --date 2025-03-23\n\n# Query cases with a specific tag\npython query_db.py --tag \"writ_petition\" --pretty\n\n# Run the complete pipeline for multiple days\npython run_pipeline.py --days 7\n</code></pre>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<ul> <li>Read the User Guide for more detailed information</li> <li>Explore the API Documentation</li> <li>Learn about the Database Integration</li> <li>Check out the Developer Guide if you want to contribute</li> </ul>"},{"location":"user-guide/api/","title":"API Documentation","text":"<p>The Open Court Data India project provides a REST API for accessing court data programmatically. This guide explains how to use the API.</p>"},{"location":"user-guide/api/#api-overview","title":"API Overview","text":"<p>The API is built with FastAPI and provides endpoints for:</p> <ul> <li>Listing available courts</li> <li>Listing available dates for a court</li> <li>Retrieving cause lists for a court on a specific date</li> <li>Searching for cases with various filters</li> <li>Retrieving details of a specific case</li> <li>Managing tags for cases</li> </ul>"},{"location":"user-guide/api/#api-base-url","title":"API Base URL","text":"<p>When running locally, the API is available at:</p> <pre><code>http://localhost:8000\n</code></pre>"},{"location":"user-guide/api/#authentication","title":"Authentication","text":"<p>Currently, the API does not require authentication. This may change in future versions.</p>"},{"location":"user-guide/api/#endpoints","title":"Endpoints","text":""},{"location":"user-guide/api/#courts","title":"Courts","text":""},{"location":"user-guide/api/#list-courts","title":"List Courts","text":"<pre><code>GET /api/courts\n</code></pre> <p>Returns a list of all available courts.</p> <p>Example Response:</p> <pre><code>[\n  {\n    \"id\": 1,\n    \"name\": \"Delhi High Court\",\n    \"code\": \"delhi_hc\",\n    \"website\": \"https://delhihighcourt.nic.in\"\n  }\n]\n</code></pre>"},{"location":"user-guide/api/#dates","title":"Dates","text":""},{"location":"user-guide/api/#list-available-dates","title":"List Available Dates","text":"<pre><code>GET /api/courts/{court_code}/dates\n</code></pre> <p>Returns a list of dates for which data is available for the specified court.</p> <p>Parameters:</p> <ul> <li><code>court_code</code>: The code of the court (e.g., <code>delhi_hc</code>)</li> </ul> <p>Example Response:</p> <pre><code>[\n  \"2025-03-23\",\n  \"2025-03-22\",\n  \"2025-03-21\"\n]\n</code></pre>"},{"location":"user-guide/api/#cause-lists","title":"Cause Lists","text":""},{"location":"user-guide/api/#get-cause-lists","title":"Get Cause Lists","text":"<pre><code>GET /api/courts/{court_code}/cause_lists/{date}\n</code></pre> <p>Returns cause lists for the specified court on the specified date.</p> <p>Parameters:</p> <ul> <li><code>court_code</code>: The code of the court (e.g., <code>delhi_hc</code>)</li> <li><code>date</code>: The date in YYYY-MM-DD format</li> </ul> <p>Example Response:</p> <pre><code>[\n  {\n    \"id\": \"123e4567-e89b-12d3-a456-426614174000\",\n    \"court\": {\n      \"id\": 1,\n      \"name\": \"Delhi High Court\",\n      \"code\": \"delhi_hc\"\n    },\n    \"bench\": {\n      \"id\": 1,\n      \"bench_number\": \"COURT NO. 01\",\n      \"judges\": \"HON'BLE CHIEF JUSTICE\"\n    },\n    \"list_date\": \"2025-03-23\",\n    \"pdf_path\": \"data/delhi_hc/cause_lists/2025-03-23/pdf1.pdf\",\n    \"cases\": [\n      {\n        \"id\": \"123e4567-e89b-12d3-a456-426614174001\",\n        \"case_number\": \"W.P.(C)-6483/2021\",\n        \"title\": \"John Doe vs State\",\n        \"item_number\": \"1\",\n        \"file_number\": \"F-123\",\n        \"petitioner_adv\": \"Mr. A\",\n        \"respondent_adv\": \"Ms. B\",\n        \"tags\": [\"writ_petition\", \"education\"]\n      }\n    ]\n  }\n]\n</code></pre>"},{"location":"user-guide/api/#cases","title":"Cases","text":""},{"location":"user-guide/api/#get-case-details","title":"Get Case Details","text":"<pre><code>GET /api/cases/{case_id}\n</code></pre> <p>Returns details of a specific case.</p> <p>Parameters:</p> <ul> <li><code>case_id</code>: The UUID of the case</li> </ul> <p>Example Response:</p> <pre><code>{\n  \"id\": \"123e4567-e89b-12d3-a456-426614174001\",\n  \"case_number\": \"W.P.(C)-6483/2021\",\n  \"title\": \"John Doe vs State\",\n  \"item_number\": \"1\",\n  \"file_number\": \"F-123\",\n  \"petitioner_adv\": \"Mr. A\",\n  \"respondent_adv\": \"Ms. B\",\n  \"cause_list\": {\n    \"id\": \"123e4567-e89b-12d3-a456-426614174000\",\n    \"court\": {\n      \"id\": 1,\n      \"name\": \"Delhi High Court\",\n      \"code\": \"delhi_hc\"\n    },\n    \"bench\": {\n      \"id\": 1,\n      \"bench_number\": \"COURT NO. 01\",\n      \"judges\": \"HON'BLE CHIEF JUSTICE\"\n    },\n    \"list_date\": \"2025-03-23\"\n  },\n  \"tags\": [\"writ_petition\", \"education\"]\n}\n</code></pre>"},{"location":"user-guide/api/#search-cases","title":"Search Cases","text":"<pre><code>GET /api/cases/search\n</code></pre> <p>Searches for cases with various filters.</p> <p>Query Parameters:</p> <ul> <li><code>court_code</code>: Filter by court code (e.g., <code>delhi_hc</code>)</li> <li><code>date</code>: Filter by date (YYYY-MM-DD)</li> <li><code>bench</code>: Filter by bench number</li> <li><code>case_number</code>: Search for a specific case number</li> <li><code>title</code>: Search in case titles</li> <li><code>tag</code>: Filter by tag</li> <li><code>limit</code>: Maximum number of results to return (default: 100)</li> <li><code>offset</code>: Offset for pagination (default: 0)</li> </ul> <p>Example Request:</p> <pre><code>GET /api/cases/search?court_code=delhi_hc&amp;date=2025-03-23&amp;tag=writ_petition\n</code></pre> <p>Example Response:</p> <pre><code>{\n  \"total\": 1,\n  \"offset\": 0,\n  \"limit\": 100,\n  \"results\": [\n    {\n      \"id\": \"123e4567-e89b-12d3-a456-426614174001\",\n      \"case_number\": \"W.P.(C)-6483/2021\",\n      \"title\": \"John Doe vs State\",\n      \"item_number\": \"1\",\n      \"file_number\": \"F-123\",\n      \"petitioner_adv\": \"Mr. A\",\n      \"respondent_adv\": \"Ms. B\",\n      \"cause_list\": {\n        \"id\": \"123e4567-e89b-12d3-a456-426614174000\",\n        \"court\": {\n          \"id\": 1,\n          \"name\": \"Delhi High Court\",\n          \"code\": \"delhi_hc\"\n        },\n        \"bench\": {\n          \"id\": 1,\n          \"bench_number\": \"COURT NO. 01\",\n          \"judges\": \"HON'BLE CHIEF JUSTICE\"\n        },\n        \"list_date\": \"2025-03-23\"\n      },\n      \"tags\": [\"writ_petition\", \"education\"]\n    }\n  ]\n}\n</code></pre>"},{"location":"user-guide/api/#tags","title":"Tags","text":""},{"location":"user-guide/api/#list-tags","title":"List Tags","text":"<pre><code>GET /api/tags\n</code></pre> <p>Returns a list of all available tags.</p> <p>Example Response:</p> <pre><code>[\n  {\n    \"id\": 1,\n    \"name\": \"writ_petition\"\n  },\n  {\n    \"id\": 2,\n    \"name\": \"education\"\n  }\n]\n</code></pre>"},{"location":"user-guide/api/#add-tag-to-case","title":"Add Tag to Case","text":"<pre><code>POST /api/cases/{case_id}/tags\n</code></pre> <p>Adds a tag to a case.</p> <p>Parameters:</p> <ul> <li><code>case_id</code>: The UUID of the case</li> </ul> <p>Request Body:</p> <pre><code>{\n  \"tag\": \"important\"\n}\n</code></pre> <p>Example Response:</p> <pre><code>{\n  \"id\": \"123e4567-e89b-12d3-a456-426614174001\",\n  \"tags\": [\"writ_petition\", \"education\", \"important\"]\n}\n</code></pre>"},{"location":"user-guide/api/#remove-tag-from-case","title":"Remove Tag from Case","text":"<pre><code>DELETE /api/cases/{case_id}/tags/{tag_name}\n</code></pre> <p>Removes a tag from a case.</p> <p>Parameters:</p> <ul> <li><code>case_id</code>: The UUID of the case</li> <li><code>tag_name</code>: The name of the tag to remove</li> </ul> <p>Example Response:</p> <pre><code>{\n  \"id\": \"123e4567-e89b-12d3-a456-426614174001\",\n  \"tags\": [\"writ_petition\", \"education\"]\n}\n</code></pre>"},{"location":"user-guide/api/#error-handling","title":"Error Handling","text":"<p>The API returns appropriate HTTP status codes for errors:</p> <ul> <li><code>400 Bad Request</code>: Invalid request parameters</li> <li><code>404 Not Found</code>: Resource not found</li> <li><code>500 Internal Server Error</code>: Server error</li> </ul> <p>Error responses include a JSON body with details:</p> <pre><code>{\n  \"detail\": \"Case not found\"\n}\n</code></pre>"},{"location":"user-guide/api/#rate-limiting","title":"Rate Limiting","text":"<p>Currently, the API does not implement rate limiting. This may change in future versions.</p>"},{"location":"user-guide/api/#using-the-api-with-python","title":"Using the API with Python","text":"<p>Here's an example of using the API with Python's <code>requests</code> library:</p> <pre><code>import requests\n\n# Base URL\nbase_url = \"http://localhost:8000\"\n\n# List courts\nresponse = requests.get(f\"{base_url}/api/courts\")\ncourts = response.json()\nprint(courts)\n\n# List available dates for Delhi HC\nresponse = requests.get(f\"{base_url}/api/courts/delhi_hc/dates\")\ndates = response.json()\nprint(dates)\n\n# Get cause lists for a specific date\nresponse = requests.get(f\"{base_url}/api/courts/delhi_hc/cause_lists/2025-03-23\")\ncause_lists = response.json()\nprint(cause_lists)\n\n# Search for cases with a specific tag\nresponse = requests.get(f\"{base_url}/api/cases/search\", params={\n    \"court_code\": \"delhi_hc\",\n    \"tag\": \"writ_petition\"\n})\ncases = response.json()\nprint(cases)\n</code></pre>"},{"location":"user-guide/api/#using-the-api-with-javascript","title":"Using the API with JavaScript","text":"<p>Here's an example of using the API with JavaScript's <code>fetch</code> API:</p> <pre><code>// Base URL\nconst baseUrl = \"http://localhost:8000\";\n\n// List courts\nfetch(`${baseUrl}/api/courts`)\n  .then(response =&gt; response.json())\n  .then(courts =&gt; console.log(courts));\n\n// List available dates for Delhi HC\nfetch(`${baseUrl}/api/courts/delhi_hc/dates`)\n  .then(response =&gt; response.json())\n  .then(dates =&gt; console.log(dates));\n\n// Get cause lists for a specific date\nfetch(`${baseUrl}/api/courts/delhi_hc/cause_lists/2025-03-23`)\n  .then(response =&gt; response.json())\n  .then(causeLists =&gt; console.log(causeLists));\n\n// Search for cases with a specific tag\nfetch(`${baseUrl}/api/cases/search?court_code=delhi_hc&amp;tag=writ_petition`)\n  .then(response =&gt; response.json())\n  .then(cases =&gt; console.log(cases));\n</code></pre>"},{"location":"user-guide/database-integration/","title":"Database Integration","text":"<p>This guide explains how the Open Court Data India project integrates with PostgreSQL to store and retrieve court data.</p>"},{"location":"user-guide/database-integration/#system-architecture","title":"System Architecture","text":"<p>The database integration follows this architecture:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Delhi HC    \u2502    \u2502 Gemini API  \u2502    \u2502 PostgreSQL  \u2502    \u2502 Frontend UI \u2502\n\u2502 Scraper     \u2502\u2500\u2500\u2500&gt;\u2502 Processing  \u2502\u2500\u2500\u2500&gt;\u2502 Database    \u2502&lt;\u2500\u2500\u2500\u2502 (React)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                           \u25b2\n                                           \u2502\n                                      \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510\n                                      \u2502 FastAPI \u2502\n                                      \u2502 Backend \u2502\n                                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"user-guide/database-integration/#database-schema","title":"Database Schema","text":"<p>The PostgreSQL database uses the following schema:</p> <pre><code>-- Courts table\nCREATE TABLE courts (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(255) NOT NULL,\n    code VARCHAR(50) NOT NULL UNIQUE,\n    website VARCHAR(255),\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Benches table\nCREATE TABLE benches (\n    id SERIAL PRIMARY KEY,\n    court_id INTEGER REFERENCES courts(id),\n    bench_number VARCHAR(50) NOT NULL,\n    judges TEXT,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n    UNIQUE(court_id, bench_number)\n);\n\n-- Cause lists table\nCREATE TABLE cause_lists (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    court_id INTEGER REFERENCES courts(id),\n    bench_id INTEGER REFERENCES benches(id),\n    list_date DATE NOT NULL,\n    pdf_path TEXT,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n    UNIQUE(court_id, bench_id, list_date)\n);\n\n-- Cases table\nCREATE TABLE cases (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    cause_list_id UUID REFERENCES cause_lists(id),\n    case_number VARCHAR(255) NOT NULL,\n    title TEXT,\n    item_number VARCHAR(50),\n    file_number VARCHAR(255),\n    petitioner_adv TEXT,\n    respondent_adv TEXT,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n    UNIQUE(cause_list_id, case_number)\n);\n\n-- Tags table\nCREATE TABLE tags (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(100) NOT NULL UNIQUE,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Case tags junction table\nCREATE TABLE case_tags (\n    case_id UUID REFERENCES cases(id),\n    tag_id INTEGER REFERENCES tags(id),\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n    PRIMARY KEY (case_id, tag_id)\n);\n</code></pre>"},{"location":"user-guide/database-integration/#database-connector","title":"Database Connector","text":"<p>The <code>DBConnector</code> class in <code>db/connector.py</code> provides a simple interface for interacting with the database. It handles:</p> <ul> <li>Connecting to the database</li> <li>Creating and retrieving courts, benches, cause lists, and cases</li> <li>Managing tags and case-tag relationships</li> <li>Querying the database with various filters</li> </ul>"},{"location":"user-guide/database-integration/#basic-usage","title":"Basic Usage","text":"<pre><code>from db.connector import DBConnector\n\n# Initialize the connector\ndb = DBConnector()\n\n# Connect to the database\ndb.connect()\n\n# Get or create a court\ncourt_id = db.get_or_create_court(\"Delhi High Court\", \"delhi_hc\")\n\n# Get or create a bench\nbench_id = db.get_or_create_bench(court_id, \"COURT NO. 01\", \"HON'BLE CHIEF JUSTICE\")\n\n# Create a cause list\ncause_list_id = db.create_cause_list(court_id, bench_id, \"2025-03-23\", \"path/to/pdf\")\n\n# Create a case\ncase_id = db.create_case(\n    cause_list_id,\n    \"W.P.(C)-6483/2021\",\n    title=\"John Doe vs State\",\n    item_number=\"1\",\n    file_number=\"F-123\",\n    petitioner_adv=\"Mr. A\",\n    respondent_adv=\"Ms. B\",\n    tags=[\"writ_petition\", \"education\"]\n)\n\n# Close the connection\ndb.close()\n</code></pre>"},{"location":"user-guide/database-integration/#environment-variables","title":"Environment Variables","text":"<p>The database connector uses the following environment variables:</p> <pre><code>DB_USER=ecourts\nDB_PASSWORD=your_password\nDB_HOST=localhost\nDB_PORT=5432\nDB_NAME=ecourts\n</code></pre> <p>You can set these in a <code>.env</code> file in the project root or export them directly in your shell.</p>"},{"location":"user-guide/database-integration/#query-tools","title":"Query Tools","text":"<p>The project includes several tools for querying the database:</p>"},{"location":"user-guide/database-integration/#command-line-interface","title":"Command Line Interface","text":"<p>The <code>query_db.py</code> script provides a command-line interface for querying the database:</p> <pre><code># List all available dates\npython query_db.py --list-dates\n\n# Query by date\npython query_db.py --date 2025-03-23 --pretty\n\n# Filter by bench number\npython query_db.py --date 2025-03-23 --bench \"COURT NO. 01\" --pretty\n\n# Search for a specific case\npython query_db.py --case \"W.P.(C)-6483/2021\" --pretty\n\n# Filter by tags\npython query_db.py --tag \"education\" --pretty\n\n# Output as JSON\npython query_db.py --date 2025-03-23 --json\n</code></pre>"},{"location":"user-guide/database-integration/#api-endpoints","title":"API Endpoints","text":"<p>The FastAPI backend provides the following endpoints for querying the database:</p> <ul> <li><code>GET /api/courts</code>: List all available courts</li> <li><code>GET /api/courts/{court_code}/dates</code>: List available dates for a court</li> <li><code>GET /api/courts/{court_code}/cause_lists/{date}</code>: Get cause lists for a court on a specific date</li> <li><code>GET /api/cases/{case_id}</code>: Get details of a specific case</li> <li><code>GET /api/cases/search</code>: Search for cases with various filters</li> </ul>"},{"location":"user-guide/database-integration/#tagging-system","title":"Tagging System","text":"<p>The database includes a tagging system for categorizing cases:</p>"},{"location":"user-guide/database-integration/#auto-tagging","title":"Auto-Tagging","text":"<p>The <code>tag_cases.py</code> script can automatically tag cases based on patterns in case numbers and titles:</p> <pre><code># Auto-tag all cases based on patterns\npython tag_cases.py --auto-tag\n</code></pre> <p>Auto-tagging rules include: - Case numbers with \"W.P.\" are tagged as \"writ_petition\" - Case numbers with \"CRL.M.C.\" are tagged as \"criminal\" - Case numbers with \"CS(COMM)\" are tagged as \"commercial\" - Titles containing \"education\" are tagged as \"education\" - And many more predefined patterns</p>"},{"location":"user-guide/database-integration/#manual-tagging","title":"Manual Tagging","text":"<p>You can also manually tag cases:</p> <pre><code># Manually tag a specific case\npython tag_cases.py --case-id \"case_uuid\" --add-tags \"important,urgent\"\n\n# Remove tags from a case\npython tag_cases.py --case-id \"case_uuid\" --remove-tags \"urgent\"\n</code></pre>"},{"location":"user-guide/database-integration/#data-processing-pipeline","title":"Data Processing Pipeline","text":"<p>The complete data pipeline integrates with the database at multiple points:</p> <ol> <li>Scraping: Downloads PDFs and saves their paths in the database</li> <li>Processing: Extracts structured data from PDFs using Gemini API</li> <li>Storage: Stores the structured data in the database</li> <li>Tagging: Automatically tags cases based on patterns</li> </ol> <p>You can run the complete pipeline with:</p> <pre><code>python run_pipeline.py\n</code></pre>"},{"location":"user-guide/database-integration/#parallel-processing","title":"Parallel Processing","text":"<p>The data processing pipeline supports parallel processing for improved performance, following the architecture established in the project:</p> <pre><code># Run the pipeline with parallel processing\npython run_pipeline.py --parallel --download-workers 5 --processing-workers 3\n</code></pre> <p>This leverages the <code>ThreadPoolExecutor</code> for both PDF downloading and Gemini API processing, with configurable worker counts to optimize performance while avoiding API rate limits.</p>"},{"location":"user-guide/overview/","title":"Overview","text":"<p>The Open Court Data India project provides tools for scraping, processing, and analyzing data from various Indian courts. This user guide will help you understand how to use the various components of the project.</p>"},{"location":"user-guide/overview/#project-components","title":"Project Components","text":"<p>The project consists of several key components:</p> <ol> <li>Scrapers: Download court data from various sources</li> <li>Data Processor: Convert unstructured data to structured formats</li> <li>Database Integration: Store and query court data</li> <li>API: Access court data programmatically</li> <li>Frontend: User interface for browsing court data</li> <li>Tagging System: Categorize cases for easier analysis</li> </ol>"},{"location":"user-guide/overview/#workflow","title":"Workflow","text":"<p>The typical workflow for using the project is:</p> <ol> <li>Scrape Data: Use the scrapers to download court data</li> <li>Process Data: Convert the data to structured formats</li> <li>Store Data: Save the structured data to the database</li> <li>Query Data: Retrieve and analyze the data</li> <li>Tag Cases: Categorize cases for easier analysis</li> <li>Access Data: Use the API or frontend to access the data</li> </ol>"},{"location":"user-guide/overview/#available-scrapers","title":"Available Scrapers","text":"<p>Currently, the project includes the following scrapers:</p> <ul> <li>Delhi High Court Cause List Scraper: Downloads cause lists from the Delhi High Court website</li> </ul>"},{"location":"user-guide/overview/#parallel-processing","title":"Parallel Processing","text":"<p>The project supports parallel processing for improved performance:</p> <ul> <li>Parallel Downloads: Download multiple PDFs concurrently</li> <li>Parallel Processing: Process multiple PDFs with Gemini API concurrently</li> </ul>"},{"location":"user-guide/overview/#data-storage","title":"Data Storage","text":"<p>The project uses PostgreSQL for structured data storage, with tables for:</p> <ul> <li>Courts</li> <li>Benches</li> <li>Cause Lists</li> <li>Cases</li> <li>Tags</li> </ul>"},{"location":"user-guide/overview/#tagging-system","title":"Tagging System","text":"<p>The project includes a tagging system for categorizing cases:</p> <ul> <li>Auto-Tagging: Automatically tag cases based on patterns</li> <li>Manual Tagging: Manually add or remove tags from cases</li> </ul>"},{"location":"user-guide/overview/#api-and-frontend","title":"API and Frontend","text":"<p>The project includes a REST API and web frontend for accessing court data:</p> <ul> <li>API: FastAPI backend with documented endpoints</li> <li>Frontend: React frontend with modern UI</li> </ul>"},{"location":"user-guide/overview/#next-steps","title":"Next Steps","text":"<p>To get started with the project, see the following guides:</p> <ul> <li>Installation</li> <li>Configuration</li> <li>Quick Start</li> </ul>"},{"location":"user-guide/scrapers/","title":"Scrapers","text":"<p>This guide explains how to use the scrapers in the Open Court Data India project.</p>"},{"location":"user-guide/scrapers/#available-scrapers","title":"Available Scrapers","text":"<p>Currently, the project includes the following scrapers:</p> <ul> <li>Delhi High Court Cause List Scraper: Downloads cause lists from the Delhi High Court website</li> </ul>"},{"location":"user-guide/scrapers/#delhi-high-court-cause-list-scraper","title":"Delhi High Court Cause List Scraper","text":"<p>The Delhi High Court Cause List Scraper downloads cause lists from the Delhi High Court website.</p>"},{"location":"user-guide/scrapers/#basic-usage","title":"Basic Usage","text":"<p>To run the scraper for today's cause lists:</p> <pre><code>python -m scrapers.delhi_hc.cause_lists.cause_list_scraper\n</code></pre>"},{"location":"user-guide/scrapers/#options","title":"Options","text":"<p>The scraper accepts the following command-line options:</p> <ul> <li><code>--date</code>, <code>-d</code>: Specify a date to scrape (YYYY-MM-DD)</li> <li><code>--output</code>, <code>-o</code>: Specify a custom output directory</li> <li><code>--debug</code>: Enable debug logging</li> <li><code>--config</code>: Specify a custom configuration file</li> <li><code>--parallel</code>: Enable parallel downloading</li> <li><code>--download-workers</code>: Number of download workers (default: 5)</li> </ul>"},{"location":"user-guide/scrapers/#examples","title":"Examples","text":"<pre><code># Scrape cause lists for a specific date\npython -m scrapers.delhi_hc.cause_lists.cause_list_scraper --date 2025-03-23\n\n# Scrape with debug logging\npython -m scrapers.delhi_hc.cause_lists.cause_list_scraper --debug\n\n# Scrape with parallel downloading\npython -m scrapers.delhi_hc.cause_lists.cause_list_scraper --parallel --download-workers 10\n\n# Scrape to a custom output directory\npython -m scrapers.delhi_hc.cause_lists.cause_list_scraper --output /path/to/output\n</code></pre>"},{"location":"user-guide/scrapers/#output","title":"Output","text":"<p>The scraper saves downloaded PDFs to the following directory structure:</p> <pre><code>data/\n\u2514\u2500\u2500 delhi_hc/\n    \u2514\u2500\u2500 cause_lists/\n        \u2514\u2500\u2500 YYYY-MM-DD/\n            \u251c\u2500\u2500 pdf1.pdf\n            \u251c\u2500\u2500 pdf1.json  # Metadata\n            \u251c\u2500\u2500 pdf2.pdf\n            \u2514\u2500\u2500 pdf2.json  # Metadata\n</code></pre> <p>The metadata JSON files contain information about the downloaded PDFs, including:</p> <ul> <li>URL</li> <li>Filename</li> <li>Download time</li> <li>Content type</li> <li>File size</li> <li>HTTP status code</li> </ul>"},{"location":"user-guide/scrapers/#database-integration","title":"Database Integration","text":"<p>The scraper can be integrated with the database using the <code>db_integrated_scraper.py</code> module:</p> <pre><code>python -m scrapers.delhi_hc.cause_lists.db_integrated_scraper\n</code></pre> <p>This version of the scraper saves the downloaded PDFs and their metadata to the database.</p>"},{"location":"user-guide/scrapers/#parallel-processing","title":"Parallel Processing","text":"<p>The scraper supports parallel processing for improved performance:</p> <pre><code>python -m scrapers.delhi_hc.cause_lists.cause_list_scraper --parallel --download-workers 5\n</code></pre> <p>This leverages the <code>ThreadPoolExecutor</code> for PDF downloading, with configurable worker counts to optimize performance.</p>"},{"location":"user-guide/scrapers/#error-handling","title":"Error Handling","text":"<p>The scraper includes robust error handling:</p> <ul> <li>Retries failed requests with exponential backoff</li> <li>Logs errors with detailed information</li> <li>Skips problematic files and continues with others</li> </ul>"},{"location":"user-guide/scrapers/#configuration","title":"Configuration","text":"<p>The scraper can be configured using the <code>config.yaml</code> file:</p> <pre><code># In config.yaml\nscrapers:\n  delhi_hc:\n    cause_list:\n      url: \"https://delhihighcourt.nic.in/causelist\"\n      max_retries: 3\n      timeout: 30\n      user_agent: \"Mozilla/5.0 ...\"\n      parallel_downloads: true\n      download_workers: 5\n</code></pre>"},{"location":"user-guide/scrapers/#complete-pipeline","title":"Complete Pipeline","text":"<p>For a complete pipeline that includes scraping, processing, and database storage, use the <code>run_pipeline.py</code> script:</p> <pre><code>python run_pipeline.py\n</code></pre> <p>This will:</p> <ol> <li>Scrape cause lists from the Delhi High Court website</li> <li>Process the PDFs with the Gemini API</li> <li>Store the structured data in the database</li> <li>Tag the cases based on patterns</li> </ol>"},{"location":"user-guide/scrapers/#future-scrapers","title":"Future Scrapers","text":"<p>The project is designed to be extensible, with plans to add scrapers for:</p> <ul> <li>Delhi High Court Judgments</li> <li>Delhi High Court Orders</li> <li>Delhi High Court Case Status</li> <li>Supreme Court of India</li> <li>Other High Courts</li> </ul>"},{"location":"user-guide/tagging-system/","title":"Tagging System","text":"<p>The Open Court Data India project includes a tagging system for categorizing cases based on their characteristics. This guide explains how to use the tagging system.</p>"},{"location":"user-guide/tagging-system/#overview","title":"Overview","text":"<p>The tagging system allows you to:</p> <ul> <li>Automatically tag cases based on patterns in case numbers and titles</li> <li>Manually add or remove tags from cases</li> <li>Filter cases by tags when querying the database</li> <li>Analyze case distributions by tag</li> </ul>"},{"location":"user-guide/tagging-system/#tag-types","title":"Tag Types","text":"<p>Tags can be used to categorize cases in various ways:</p> <ul> <li>Case Type: writ_petition, criminal, civil, commercial, etc.</li> <li>Subject Matter: education, property, taxation, etc.</li> <li>Status: urgent, important, disposed, etc.</li> <li>Custom Tags: Any user-defined categories</li> </ul>"},{"location":"user-guide/tagging-system/#auto-tagging","title":"Auto-Tagging","text":"<p>The project includes an auto-tagging system that can automatically assign tags to cases based on patterns in case numbers and titles.</p>"},{"location":"user-guide/tagging-system/#running-auto-tagging","title":"Running Auto-Tagging","text":"<p>To run auto-tagging on all cases in the database:</p> <pre><code>python tag_cases.py --auto-tag\n</code></pre>"},{"location":"user-guide/tagging-system/#auto-tagging-rules","title":"Auto-Tagging Rules","text":"<p>The auto-tagging system uses the following rules:</p>"},{"location":"user-guide/tagging-system/#case-number-patterns","title":"Case Number Patterns","text":"<ul> <li>Writ Petitions: Case numbers containing \"W.P.\" are tagged as \"writ_petition\"</li> <li>Criminal Cases: Case numbers containing \"CRL.M.C.\", \"CRL.A.\", etc. are tagged as \"criminal\"</li> <li>Civil Cases: Case numbers containing \"CS\", \"RFA\", etc. are tagged as \"civil\"</li> <li>Commercial Cases: Case numbers containing \"CS(COMM)\" are tagged as \"commercial\"</li> <li>Appeals: Case numbers containing \"LPA\", \"RFA\", etc. are tagged as \"appeal\"</li> </ul>"},{"location":"user-guide/tagging-system/#title-patterns","title":"Title Patterns","text":"<ul> <li>Education: Titles containing \"education\", \"school\", \"university\", etc. are tagged as \"education\"</li> <li>Property: Titles containing \"property\", \"land\", \"rent\", etc. are tagged as \"property\"</li> <li>Taxation: Titles containing \"tax\", \"GST\", \"income tax\", etc. are tagged as \"taxation\"</li> <li>Employment: Titles containing \"employment\", \"service\", \"pension\", etc. are tagged as \"employment\"</li> </ul>"},{"location":"user-guide/tagging-system/#customizing-auto-tagging-rules","title":"Customizing Auto-Tagging Rules","text":"<p>You can customize the auto-tagging rules by editing the <code>tag_cases.py</code> script. Look for the <code>auto_tag_cases</code> function and modify the pattern matching rules.</p>"},{"location":"user-guide/tagging-system/#manual-tagging","title":"Manual Tagging","text":"<p>You can manually add or remove tags from cases using the <code>tag_cases.py</code> script.</p>"},{"location":"user-guide/tagging-system/#listing-tags","title":"Listing Tags","text":"<p>To list all tags in the database:</p> <pre><code>python tag_cases.py --list-tags\n</code></pre>"},{"location":"user-guide/tagging-system/#adding-tags","title":"Adding Tags","text":"<p>To add tags to a case:</p> <pre><code>python tag_cases.py --case-id \"case_uuid\" --add-tags \"important,urgent\"\n</code></pre> <p>You can specify multiple tags separated by commas.</p>"},{"location":"user-guide/tagging-system/#removing-tags","title":"Removing Tags","text":"<p>To remove tags from a case:</p> <pre><code>python tag_cases.py --case-id \"case_uuid\" --remove-tags \"urgent\"\n</code></pre>"},{"location":"user-guide/tagging-system/#finding-a-case-id","title":"Finding a Case ID","text":"<p>To find the UUID of a case, you can use the <code>query_db.py</code> script:</p> <pre><code>python query_db.py --case \"W.P.(C)-6483/2021\" --pretty\n</code></pre> <p>This will display the case details, including its UUID.</p>"},{"location":"user-guide/tagging-system/#querying-by-tags","title":"Querying by Tags","text":"<p>You can filter cases by tags when querying the database:</p> <pre><code># Query cases with a specific tag\npython query_db.py --tag \"writ_petition\" --pretty\n\n# Combine with other filters\npython query_db.py --date 2025-03-23 --tag \"writ_petition\" --pretty\n</code></pre>"},{"location":"user-guide/tagging-system/#api-integration","title":"API Integration","text":"<p>The tagging system is integrated with the API:</p>"},{"location":"user-guide/tagging-system/#listing-tags_1","title":"Listing Tags","text":"<pre><code>GET /api/tags\n</code></pre> <p>Returns a list of all available tags.</p>"},{"location":"user-guide/tagging-system/#adding-tags_1","title":"Adding Tags","text":"<pre><code>POST /api/cases/{case_id}/tags\n</code></pre> <p>Adds a tag to a case.</p>"},{"location":"user-guide/tagging-system/#removing-tags_1","title":"Removing Tags","text":"<pre><code>DELETE /api/cases/{case_id}/tags/{tag_name}\n</code></pre> <p>Removes a tag from a case.</p>"},{"location":"user-guide/tagging-system/#filtering-by-tags","title":"Filtering by Tags","text":"<pre><code>GET /api/cases/search?tag=writ_petition\n</code></pre> <p>Returns cases with the specified tag.</p>"},{"location":"user-guide/tagging-system/#frontend-integration","title":"Frontend Integration","text":"<p>The frontend includes a tagging interface:</p> <ul> <li>View tags for each case</li> <li>Add or remove tags from cases</li> <li>Filter cases by tags</li> <li>View tag statistics</li> </ul>"},{"location":"user-guide/tagging-system/#tag-analysis","title":"Tag Analysis","text":"<p>The tagging system enables various analyses:</p> <ul> <li>Distribution of case types</li> <li>Subject matter trends over time</li> <li>Identification of important or urgent cases</li> <li>Custom categorizations for research purposes</li> </ul>"},{"location":"user-guide/tagging-system/#database-schema","title":"Database Schema","text":"<p>The tagging system uses the following database schema:</p> <pre><code>-- Tags table\nCREATE TABLE tags (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(100) NOT NULL UNIQUE,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Case tags junction table\nCREATE TABLE case_tags (\n    case_id UUID REFERENCES cases(id),\n    tag_id INTEGER REFERENCES tags(id),\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n    PRIMARY KEY (case_id, tag_id)\n);\n</code></pre> <p>This schema allows for a many-to-many relationship between cases and tags.</p>"}]}